{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5617c5-cab4-4e2d-bc24-be58a4f2bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec001a68-1e74-47ee-9d46-04058236ec27",
   "metadata": {},
   "source": [
    "## open antiberty filtered and rosetta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661d952-cf5b-47e9-8d90-c75ba16b2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_H = \"AntiBERTy filtered files/H-AntiBERTy\"\n",
    "output_folder_L = \"AntiBERTy filtered files/L-AntiBERTy\"\n",
    "\n",
    "# Create dictionaries to store DataFrames\n",
    "antiberty_h_dataframes = {}\n",
    "antiberty_l_dataframes = {}\n",
    "\n",
    "# Read CSV files for H-chain\n",
    "for custom_name in os.listdir(output_folder_H):\n",
    "    file_path = os.path.join(output_folder_H, custom_name)\n",
    "    if os.path.isfile(file_path) and file_path.endswith(\".csv\"):\n",
    "        antiberty_h_dataframes[custom_name[:-4]] = pd.read_csv(file_path)\n",
    "\n",
    "# Read CSV files for L-chain\n",
    "for custom_name in os.listdir(output_folder_L):\n",
    "    file_path = os.path.join(output_folder_L, custom_name)\n",
    "    if os.path.isfile(file_path) and file_path.endswith(\".csv\"):\n",
    "        antiberty_l_dataframes[custom_name[:-4]] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b7c0e-f16e-484c-8154-b34203d05e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_H = \"Rosetta filtered files/H-rosetta\"\n",
    "output_folder_L = \"Rosetta filtered files/L-rosetta\"\n",
    "\n",
    "# Create dictionaries to store DataFrames\n",
    "rosetta_h_dataframes = {}\n",
    "rosetta_l_dataframes = {}\n",
    "\n",
    "# Read CSV files for H-chain\n",
    "for custom_name in os.listdir(output_folder_H):  # lists all the files in the folder\n",
    "    file_path = os.path.join(output_folder_H, custom_name) # os.path.join takes the path and joins them\n",
    "    if os.path.isfile(file_path) and file_path.endswith(\".csv\"):\n",
    "        rosetta_h_dataframes[custom_name[:-4]] = pd.read_csv(file_path)  # saves the custom names without the \".csv\"\n",
    "\n",
    "# Read CSV files for L-chain\n",
    "for custom_name in os.listdir(output_folder_L):\n",
    "    file_path = os.path.join(output_folder_L, custom_name)  # in brakets - output folder - is were we save it, custom_name is the file (we iterate)\n",
    "    if os.path.isfile(file_path) and file_path.endswith(\".csv\"):  # ensures the file_path points to a file and that the file ends with csv\n",
    "        rosetta_l_dataframes[custom_name[:-4]] = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb55499-e724-4171-963a-a414b8f6470e",
   "metadata": {},
   "source": [
    "## Merge the rosetta and antiberty dataframe\n",
    "polish the dataframes, rename desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b56d0c-3aed-48d1-b484-c1bf488bfc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "antibody_h_chain_scores ={}\n",
    "antibody_l_chain_scores ={}\n",
    "\n",
    "for custom_name, df in antiberty_h_dataframes.items():  # iterate trough the dictionary\n",
    "    if custom_name in rosetta_h_dataframes:  # makes sure the names match\n",
    "\n",
    "        \"\"\"\n",
    "        because the positions in both dataframes do not match (be a string) we need to make them a string\n",
    "        then we merge the dataframes based on the position (foremost)\n",
    "        we drop unecessary columns and rename the columns for ease\n",
    "        laslty we reorder the columns in the desired order (to make it easier to read)\n",
    "        \"\"\"\n",
    "        df[\"position\"] = df[\"position\"].astype(str)\n",
    "        rosetta_h_dataframe = rosetta_h_dataframes[custom_name].astype({\"position\": str})\n",
    "        df = df.merge(rosetta_h_dataframe, on=[\"position\", \"WT_AA\", \"MUT_AA\"])     \n",
    "        df = df.drop(columns = [\"res_code\", \"pdb_numbering\",\"VorC\"])\n",
    "        df = df.rename(columns = {\"mean_ddG\": \"Rosetta score\", \"imgt_numbering\": \"IMGT numbering\"})        \n",
    "        df = df.reindex(columns = [\"chain\", \"position\", \"IMGT numbering\", \"WT_AA\", \"MUT_AA\", \"Scaled Antiberty Score\", \"Rosetta score\"])\n",
    "        antibody_h_chain_scores[custom_name] = df\n",
    "\n",
    "\n",
    "for custom_name, df in antiberty_l_dataframes.items():\n",
    "    if custom_name in rosetta_l_dataframes:\n",
    "        df[\"position\"] = df[\"position\"].astype(str)\n",
    "        rosetta_l_dataframe = rosetta_l_dataframes[custom_name].astype({\"position\": str})\n",
    "        df = df.merge(rosetta_l_dataframe, on=[\"position\", \"WT_AA\", \"MUT_AA\"])        \n",
    "        df = df.drop(columns = [\"res_code\", \"pdb_numbering\",\"VorC\"])\n",
    "        df = df.rename(columns = {\"mean_ddG\": \"Rosetta score\", \"imgt_numbering\": \"IMGT numbering\"})\n",
    "        df = df.reindex(columns = [\"chain\", \"position\",\"IMGT numbering\", \"WT_AA\", \"MUT_AA\", \"Scaled Antiberty Score\", \"Rosetta score\"])\n",
    "        antibody_l_chain_scores[custom_name] = df\n",
    "\n",
    "# for custom_name, df in antibody_h_chain_scores.items():\n",
    "#     print(f\"Custom Name: {custom_name}\")\n",
    "#     display(df)\n",
    "# for custom_name, df in antibody_l_chain_scores.items():\n",
    "#     print(f\"Custom Name: {custom_name}\")\n",
    "#     display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2bdefa-1cc1-44bf-b8cf-cb8eaae4399c",
   "metadata": {},
   "source": [
    "# Merge rosetta and antiberty H- and L-chain dataframes\n",
    "calculate the arcsin (to normalise data)\n",
    "\n",
    "## Remove empty dataframes\n",
    "After I performed the correlation calculations, I found that there are some empty dataframes. I checked to make sure there were no mistakes, and it appears that the raw files (original -Rosetta) have always been empty. Since this is not a mistake that happened during the table merging, I will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b1230-c573-480e-ae3e-cb0a4ce7d7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_dataframes = {}\n",
    "\n",
    "# for custom_name in set(antibody_l_chain_scores.keys()) & set(antibody_h_chain_scores.keys()):\n",
    "#     concatenated_df = pd.concat([antibody_l_chain_scores[custom_name], antibody_h_chain_scores[custom_name]])\n",
    "#     clean_dataframes[custom_name] = concatenated_df\n",
    "\n",
    "for custom_name, df_l in antibody_l_chain_scores.items():\n",
    "    if custom_name in antibody_h_chain_scores:\n",
    "        df_h = antibody_h_chain_scores[custom_name]  # saves dataframe under value_H\n",
    "        concatenated_df = pd.concat([df_l, df_h])\n",
    "        concatenated_df[\"IMGT numbering\"] = concatenated_df[\"IMGT numbering\"].astype(str)\n",
    "        concatenated_df[\"pos\"] = concatenated_df[\"IMGT numbering\"].apply(lambda x: ''.join(filter(str.isdigit, x)))\n",
    "        concatenated_df[\"insertion_code\"] = concatenated_df[\"IMGT numbering\"].apply(lambda x: ''.join(filter(str.isalpha, x)))\n",
    "        concatenated_df[\"AntiBERTy normalised\"] = np.arcsinh(concatenated_df[\"Scaled Antiberty Score\"])\n",
    "        concatenated_df[\"Rosetta normalised\"] = np.arcsinh(concatenated_df[\"Rosetta score\"])\n",
    "        if not concatenated_df.empty:\n",
    "            clean_dataframes[custom_name] = concatenated_df\n",
    "\n",
    "# for custom_name, df in clean_dataframes.items():\n",
    "#     print(f\"Custom Name: {custom_name}\")\n",
    "#     display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780a6d2-1490-4475-a9bd-a44374ad2d17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_region(row):\n",
    "    pos = row['pos']\n",
    "    if pos <= 15:\n",
    "        return 'FR1-A'\n",
    "    elif 16 <= pos <= 26:\n",
    "        return 'FR1-B'\n",
    "    elif 27 <= pos <= 38:\n",
    "        return 'CDR1'\n",
    "    elif 39 <= pos <= 46:\n",
    "        return 'FR2-C'\n",
    "    elif 47 <= pos <= 55:\n",
    "        return \"FR2-C'\"\n",
    "    elif 56 <= pos <= 65:\n",
    "        return 'CDR2'\n",
    "    elif 66 <= pos <= 74:\n",
    "        return 'FR3-C\"'\n",
    "    elif 75 <= pos <= 84:\n",
    "        return 'FR3-D'\n",
    "    elif 85 <= pos <= 96:\n",
    "        return 'FR3-E'\n",
    "    elif 97 <= pos <= 104:\n",
    "        return 'FR3-F'\n",
    "    elif 105 <= pos <= 117:\n",
    "        return 'CDR3'\n",
    "    else:\n",
    "        return 'FR4'\n",
    "\n",
    "for custom_name, df in clean_dataframes.items():\n",
    "    if 'pos' in df.columns:\n",
    "        # Convert 'pos' column to int\n",
    "        df['pos'] = df['pos'].astype(int)\n",
    "\n",
    "        # Create a new column \"region\" and apply the logic\n",
    "        df['region'] = df.apply(assign_region, axis=1)\n",
    "    else:\n",
    "        print(f'Warning: DataFrame {custom_name} does not have a \"pos\" column.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902844-11cb-44df-8e3c-9b962a4228a8",
   "metadata": {},
   "source": [
    "## save the files as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0565e-7090-48e1-bdcc-6a661fdd14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"Clean files/\"\n",
    "\n",
    "for custom_name, df in clean_dataframes.items():\n",
    "    file_path = os.path.join(output_folder, f\"{custom_name}.csv\")  # joins files to the output folder\n",
    "    df.to_csv(file_path, index=False)  # index = False removes the index in the csv files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
