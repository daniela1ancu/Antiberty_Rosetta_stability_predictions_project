{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99055b43-795c-4e3c-b8bf-a555baf22d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df957c3d-2b7a-4fb9-9236-598edddc1dda",
   "metadata": {},
   "source": [
    "## Read the files and sort them\n",
    "the files are names something like 1rzi_NM_N or 1rzi_NM_M.\n",
    "\n",
    "The first letter is always the heavy chain whilst the second is always the ligth chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a8597c-4621-425a-9267-e1c3cbb2645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Surface information/H chain\", exist_ok=True)\n",
    "os.makedirs(\"Surface information/L chain\", exist_ok=True)\n",
    "\n",
    "input_folder = \"Initial data/iso_rpopsResidue\"\n",
    "surface_info_dataframes = {}\n",
    "\n",
    "def sort_information(input_folder):\n",
    "    \"\"\"\n",
    "    for a file named 1rzi_NM_N or 1rzi_NM_M:\n",
    "    file[8:9] = NM\n",
    "    file[5:6] = N (heavy chain)\n",
    "    file[6:7] = M (light chain)\n",
    "    this function is used to copy files into a new folder and rename them to contain the first 6 characters in the file: 1rzi_NM\n",
    "    \"\"\"\n",
    "    \n",
    "    for file in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        # print(file[5:6], file[6:7], file[:7])\n",
    "        \n",
    "        if file[8:9] == file[5:6]:\n",
    "            # Copy file to H chain directory\n",
    "            custom_name = file[:7]\n",
    "            destination_path = os.path.join(\"Surface information/H chain\", custom_name)\n",
    "            shutil.copyfile(file_path, destination_path)\n",
    "\n",
    "        elif file[8:9] == file[6:7]:\n",
    "            # Copy file to L chain directory\n",
    "            custom_name = file[:7]\n",
    "            destination_path = os.path.join(\"Surface information/L chain\", custom_name)\n",
    "            shutil.copyfile(file_path, destination_path)\n",
    "            \n",
    "        else:\n",
    "            print(file_path)\n",
    "\n",
    "sort_information(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e963a84-ef81-4329-ae37-ec30e387a323",
   "metadata": {},
   "source": [
    "## Convert to dataframes\n",
    "\n",
    "the text files will be converted to dataframes, which will then be concatenated so each file will contain both the heavy and the light chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7669b54c-445d-4bfd-92ff-77ece3a8c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_chain_input_folder = \"Surface information/H chain\"\n",
    "light_chain_input_folder = \"Surface information/L chain\"\n",
    "HC_dataframe = {}\n",
    "LC_dataframe = {}\n",
    "conc_dataframes = {}\n",
    "\n",
    "def read_files(input_folder):\n",
    "    \"\"\"\n",
    "    this function takes the files converts them to dataframes and then formats the columns \n",
    "    NOTE - had to do it this way since the format of the file was a bit off.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    files = os.listdir(input_folder)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        custom_name = file[:7]\n",
    "\n",
    "        column_names = [\"ResidNe\", \"Chain\", \"ResidNr\", \"iCode\", \"Phob/A^2\", \"Phil/A^2\", \"SASA/A^2\", \"Q(SASA)\", \"N(overl)\", \"Surf/A^2\"]\n",
    "        \n",
    "        with open(file_path, \"r\") as f:\n",
    "            # Read dataframe from file with specified column names and delimiter\n",
    "            df = pd.read_csv(f, delimiter=\"\\t\", names=column_names, skiprows=1)\n",
    "        \n",
    "        if input_folder == heavy_chain_input_folder:\n",
    "            # df = df.rename(columns={\"Unnamed: 5\": \"Phil/A^2\"})\n",
    "            df[\"Chain\"] = \"H\"\n",
    "            HC_dataframe[custom_name] = df\n",
    "        elif input_folder == light_chain_input_folder:\n",
    "            df[\"Chain\"] = \"L\"\n",
    "            LC_dataframe[custom_name] = df\n",
    "\n",
    "read_files(heavy_chain_input_folder)\n",
    "read_files(light_chain_input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10012cf0-0d52-4049-b666-9e327610a21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5a7x_DC\n",
      "5kzp_GK\n",
      "2hlf_CD\n",
      "7s7i_YZ\n",
      "2fat_HL\n",
      "4uom_HL\n",
      "5a8h_DC\n",
      "8ds5_CB\n",
      "1rzi_NM\n",
      "7s11_IM\n",
      "5a8h_JI\n",
      "2jix_DG\n",
      "5v2a_HL\n",
      "2dwe_AB\n",
      "1dqd_HL\n",
      "1rzk_HL\n",
      "3pjs_BA\n",
      "7s7i_HL\n",
      "1r24_BA\n",
      "5a8h_PO\n",
      "4hg4_Zz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ni had a look and it appears that these names are not in the \"clean files\".\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for custom_name, df in HC_dataframe.items():\n",
    "    if custom_name in LC_dataframe:\n",
    "        L_chain = LC_dataframe[custom_name]\n",
    "        conc_dataframes[custom_name] = pd.concat([df, L_chain])\n",
    "    else:\n",
    "        print(custom_name)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "i had a look and it appears that these names are not in the \"clean files\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33688504-44cb-457e-86a9-2cdbf40c3a01",
   "metadata": {},
   "source": [
    "## Add a column with the one letter code\n",
    "\n",
    "This will help us successfuly merge these files with the \"clean files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d615b6f-e7e7-4a8b-8b28-82281eecf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "started off with only one dataframe\n",
    "\"\"\"\n",
    "amino_acids_mapping = {\n",
    "    \"ALA\": \"A\",\n",
    "    \"ARG\": \"R\",\n",
    "    \"ASN\": \"N\",\n",
    "    \"ASP\": \"D\",\n",
    "    \"CYS\": \"C\",\n",
    "    \"GLN\": \"Q\",\n",
    "    \"GLU\": \"E\",\n",
    "    \"GLY\": \"G\",\n",
    "    \"HIS\": \"H\",\n",
    "    \"ILE\": \"I\",\n",
    "    \"LEU\": \"L\",\n",
    "    \"LYS\": \"K\",\n",
    "    \"MET\": \"M\",\n",
    "    \"PHE\": \"F\",\n",
    "    \"PRO\": \"P\",\n",
    "    \"SER\": \"S\",\n",
    "    \"THR\": \"T\",\n",
    "    \"TRP\": \"W\",\n",
    "    \"TYR\": \"Y\",\n",
    "    \"VAL\": \"V\"\n",
    "}\n",
    "\n",
    "dataframe = conc_dataframes[\"7mn8_DC\"].copy()\n",
    "\n",
    "dataframe[\"WT_AA\"] = dataframe[\"ResidNe\"].str.strip()\n",
    "dataframe[\"WT_AA\"] = dataframe[\"WT_AA\"].map(amino_acids_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c0fcee1-5c0a-45c1-a01e-fd6ddd25944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where CSV files will be saved\n",
    "file_path = \"Surface information/surface_access_clean_files\"\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "# Mapping of three-letter amino acid codes to one-letter amino acid codes\n",
    "amino_acids_mapping = {\n",
    "    \"ALA\": \"A\",\n",
    "    \"ARG\": \"R\",\n",
    "    \"ASN\": \"N\",\n",
    "    \"ASP\": \"D\",\n",
    "    \"CYS\": \"C\",\n",
    "    \"GLN\": \"Q\",\n",
    "    \"GLU\": \"E\",\n",
    "    \"GLY\": \"G\",\n",
    "    \"HIS\": \"H\",\n",
    "    \"ILE\": \"I\",\n",
    "    \"LEU\": \"L\",\n",
    "    \"LYS\": \"K\",\n",
    "    \"MET\": \"M\",\n",
    "    \"PHE\": \"F\",\n",
    "    \"PRO\": \"P\",\n",
    "    \"SER\": \"S\",\n",
    "    \"THR\": \"T\",\n",
    "    \"TRP\": \"W\",\n",
    "    \"TYR\": \"Y\",\n",
    "    \"VAL\": \"V\"\n",
    "}\n",
    "\n",
    "# Dictionary to store modified DataFrames (not used in the current code)\n",
    "solvent_access_info = {}\n",
    "\n",
    "def add_one_letter_code():\n",
    "    \"\"\"\n",
    "    Function to add a new column containing one-letter amino acid codes to each DataFrame.\n",
    "    \n",
    "    Creates a copy of the DataFrame to avoid modifying the original.\n",
    "    Strips any whitespace from the \"ResidNe\" column values and adds them to a new column \"WT_AA\".\n",
    "    Maps the three-letter amino acid codes to one-letter codes using the defined mapping.\n",
    "    Constructs the file path for saving the DataFrame to a CSV file.\n",
    "    Saves the modified DataFrame to a CSV file without the index.\n",
    "    Optionally, stores the modified DataFrame in the dictionary (currently not used).\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    for custom_name, df in conc_dataframes.items():\n",
    "        dataframe = df.copy()\n",
    "        dataframe[\"WT_AA\"] = dataframe[\"ResidNe\"].str.strip()\n",
    "        dataframe[\"WT_AA\"] = dataframe[\"WT_AA\"].map(amino_acids_mapping)\n",
    "        dataframe_file_path = os.path.join(file_path, f\"{custom_name}.csv\")\n",
    "        dataframe.to_csv(dataframe_file_path, index=False)\n",
    "        # solvent_access_info[custom_name] = dataframe\n",
    "        \n",
    "\n",
    "add_one_letter_code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
