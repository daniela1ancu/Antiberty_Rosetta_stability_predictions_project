{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba8616-57ef-4895-ad64-3c43a99a2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4f609-6270-4dca-bfe5-833cb26f3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"Clean files/\"\n",
    "dataframes = {}\n",
    "\n",
    "def open_dataframes(input_folder):\n",
    "    for file in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            custom_name = file[:-4]\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes[custom_name] = df\n",
    "\n",
    "open_dataframes(input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd62561-c4b1-49e5-b025-4780f0f3c1a7",
   "metadata": {},
   "source": [
    "## Calculate the correlation for the entire variable region\n",
    ".corr to calculate the Pearsons correlation (default) and then also the Spearman (to see if there are some non-linear trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98467759-f4b5-4572-b8ad-6f6891b4872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_corr_df_pearson = {}\n",
    "positive_corr_df_spearman = {}\n",
    "negative_corr_df = {}\n",
    "unknown_dataframes = {}\n",
    "\n",
    "\n",
    "for custom_name, df in dataframes.items():\n",
    "    pearson_correlation = df[\"AntiBERTy normalised\"].corr(df[\"Rosetta normalised\"], method = \"pearson\")\n",
    "    spearman_correlation = df[\"AntiBERTy normalised\"].corr(df[\"Rosetta normalised\"], method = \"spearman\")\n",
    "    \n",
    "    # print(f\"AntiBERTy and Rosetta scores correlations {custom_name}: Pearson:{pearson_correlation}, Spearman:{spearman_correlation}\\n\")\n",
    "\n",
    "    if pearson_correlation > 0:\n",
    "        positive_corr_df_pearson[custom_name] = df\n",
    "    elif spearman_correlation > 0:\n",
    "        positive_corr_df_spearman[custom_name] = df\n",
    "    elif pearson_correlation < 0 and spearman_correlation < 0:\n",
    "        negative_corr_df[custom_name] = df\n",
    "    else:\n",
    "        unknown_dataframes[custom_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94f6ce-8de0-4ef1-b82b-aa03fb41cc3d",
   "metadata": {},
   "source": [
    "# Calculate correlation for H and L chain:\n",
    "Using the filtered dataframes we can calculate the correlation between the scores and see which ones are the highest, lowest as well as which chain has the stronger correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8af58-dc68-46e7-a760-e268d8fcde8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To do this we can create a dictionary where all the correlations, variance and standard deviation\n",
    "THIS DOES NOT SAVE THE DATAFRAMES, only the values. The dataframes can be accessed like normal by calling \"dataframes\"\n",
    "there are four main categories two for each chain - positive and negative \n",
    "this is further divided based on which correlation type is positive/negative (both, only spearman or only pearson)\n",
    "[f\"positive_{chain_category.lower()}\"] this would result in positive_l or positive_h based on the chain_category\n",
    "\"\"\"\n",
    "correlation_data = {\n",
    "    \"positive_h\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"negative_h\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"positive_l\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"negative_l\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"unknown\": {}\n",
    "}\n",
    "\n",
    "def calculate_correlation(chain_value, dictionary, custom_name):\n",
    "    pearson_correlation = chain_value[\"AntiBERTy normalised\"].corr(chain_value[\"Rosetta normalised\"])\n",
    "    spearman_correlation = chain_value[\"AntiBERTy normalised\"].corr(chain_value[\"Rosetta normalised\"], method = \"spearman\")\n",
    "    variance = np.var(chain_value[\"AntiBERTy normalised\"] - chain_value[\"Rosetta normalised\"])\n",
    "    std_dev = np.sqrt(variance)\n",
    "\n",
    "    chain_category = chain_value.iloc[0][\"chain\"]  # this locates the chain type\n",
    "    \n",
    "    if pearson_correlation > 0 and spearman_correlation > 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"both\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation < 0 and spearman_correlation < 0:\n",
    "        dictionary[f\"negative_{chain_category.lower()}\"][\"both\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation < 0 and spearman_correlation > 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"spearman\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation > 0 and spearman_correlation < 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"pearson\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    else:\n",
    "        dictionary[\"unknown\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    \n",
    "    return pearson_correlation, spearman_correlation, variance, std_dev\n",
    "    \n",
    "for custom_name, df in dataframes.items():\n",
    "    chain_data_h = df[df[\"chain\"] == \"H\"]  # this would be the chain_value\n",
    "    chain_data_l = df[df[\"chain\"] == \"L\"]\n",
    "    \n",
    "    pearson_correlation_h, spearman_correlation_h, variability_h, std_dev_h = calculate_correlation(\n",
    "        chain_data_h, correlation_data, custom_name\n",
    "    )\n",
    "    pearson_correlation_l, spearman_correlation_l, variability_l, std_dev_l = calculate_correlation(\n",
    "        chain_data_l, correlation_data, custom_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc6151c-8348-4839-b70b-9c30b30da831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(correlation_data[\"positive_h\"][\"pearson\"]))\n",
    "print(len(correlation_data[\"positive_h\"][\"spearman\"]))\n",
    "print(len(correlation_data[\"positive_h\"][\"both\"]))\n",
    "print(len(correlation_data[\"negative_h\"][\"both\"]))\n",
    "\n",
    "print(len(correlation_data[\"positive_l\"][\"pearson\"]))\n",
    "print(len(correlation_data[\"positive_l\"][\"spearman\"]))\n",
    "print(len(correlation_data[\"positive_l\"][\"both\"]))\n",
    "print(len(correlation_data[\"negative_l\"][\"both\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c737c5-17c6-4a60-95de-784e1b00c8a5",
   "metadata": {},
   "source": [
    "# Calculate correlations for CDRs only\n",
    "Take the amino acids (for each file) and calculate the correlations for this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef24112-228c-4343-b82b-aac66864d463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CDRs_correlation_data = {\n",
    "    \"positive_h\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"negative_h\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"positive_l\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "    \"negative_l\": {\"pearson\": {}, \"spearman\": {}, \"both\": {}},\n",
    "}\n",
    "\n",
    "def calculate_correlation_regions(chain_value, dictionary, custom_name):\n",
    "    region_value = chain_value[chain_value[\"region\"].isin([\"CDR1\", \"CDR2\", \"CDR3\"])]\n",
    "    pearson_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"])\n",
    "    spearman_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"], method=\"spearman\")\n",
    "    variance = np.var(region_value[\"AntiBERTy normalised\"] - region_value[\"Rosetta normalised\"])\n",
    "    std_dev = np.sqrt(variance)\n",
    "    \n",
    "    chain_category = region_value.iloc[0][\"chain\"]\n",
    "\n",
    "    if pearson_correlation > 0 and spearman_correlation > 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"both\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation < 0 and spearman_correlation < 0:\n",
    "        dictionary[f\"negative_{chain_category.lower()}\"][\"both\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation < 0 and spearman_correlation > 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"spearman\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    elif pearson_correlation > 0 and spearman_correlation < 0:\n",
    "        dictionary[f\"positive_{chain_category.lower()}\"][\"pearson\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    else:\n",
    "        dictionary[\"unknown_dataframes\"][custom_name] = (pearson_correlation, spearman_correlation, variance, std_dev)\n",
    "    \n",
    "    return pearson_correlation, spearman_correlation, variance, std_dev\n",
    "\n",
    "for custom_name, df in dataframes.items():\n",
    "    chain_data_h = df[df[\"chain\"] == \"H\"]\n",
    "    chain_data_l = df[df[\"chain\"] == \"L\"]\n",
    "\n",
    "    pearson_correlation_h, spearman_correlation_h, variability_h, std_dev_h = calculate_correlation_regions(\n",
    "        chain_data_h, CDRs_correlation_data, custom_name\n",
    "    )\n",
    "    pearson_correlation_l, spearman_correlation_l, variability_l, std_dev_l = calculate_correlation_regions(\n",
    "        chain_data_l, CDRs_correlation_data, custom_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6424cf-46a8-4461-a6bd-148d88e1472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(CDRs_correlation_data[\"positive_h\"][\"pearson\"]))\n",
    "print(len(CDRs_correlation_data[\"positive_h\"][\"spearman\"]))\n",
    "print(len(CDRs_correlation_data[\"positive_h\"][\"both\"]))\n",
    "print(len(CDRs_correlation_data[\"negative_h\"][\"both\"]))\n",
    "\n",
    "print(len(CDRs_correlation_data[\"positive_l\"][\"pearson\"]))\n",
    "print(len(CDRs_correlation_data[\"positive_l\"][\"spearman\"]))\n",
    "print(len(CDRs_correlation_data[\"positive_l\"][\"both\"]))\n",
    "print(len(CDRs_correlation_data[\"negative_l\"][\"both\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ef4f0-6bc8-4bcf-826c-bb1543917ea0",
   "metadata": {},
   "source": [
    "# Calculate correlations for each region\n",
    "Take the amino acids (for each file) and calculate the correlations for every region in the variable region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee29c6-9e34-4b6f-905e-7169062d6e69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "regions = [\"FR1-A\", \"FR1-B\", \"CDR1\", \"FR2-C\", \"FR2-C'\", \"CDR2\", 'FR3-C\"', \"FR3-D\", \"FR3-E\", \"FR3-F\", \"CDR3\", \"FR4\"]\n",
    "\n",
    "for region in regions:\n",
    "    result_dict[region] = {\n",
    "        \"positive_corr_df\": {\"H\": {\"both\": {}, \"pearson\": {}, \"spearman\": {}}, \"L\": {\"both\": {}, \"pearson\": {}, \"spearman\": {}}},\n",
    "        \"negative_corr_df\": {\"H\": {\"both\": {}, \"pearson\": {}, \"spearman\": {}}, \"L\": {\"both\": {}, \"pearson\": {}, \"spearman\": {}}},\n",
    "    }\n",
    "\n",
    "unknown_dataframes = {}\n",
    "\n",
    "min_corr_H = float('inf')\n",
    "max_corr_H = float('-inf')\n",
    "\n",
    "min_corr_L = float('inf')\n",
    "max_corr_L = float('-inf')\n",
    "\n",
    "def calculate_correlation_regions(df, chain, result_dict, custom_name):\n",
    "    global min_corr_H, max_corr_H, min_corr_L, max_corr_L\n",
    "    # print(f\"Processing {custom_name} for region {region} and chain {chain}\")\n",
    "    chain_value = df[df[\"chain\"] == chain]\n",
    "    region_value = chain_value[chain_value[\"region\"] == region]\n",
    "    pearson_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"])\n",
    "    spearman_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"], method = \"spearman\")\n",
    "    variance = np.var(region_value[\"AntiBERTy normalised\"] - region_value[\"Rosetta normalised\"])\n",
    "    std_dev = np.sqrt(variance)\n",
    "\n",
    "    if chain == \"H\":\n",
    "        if spearman_correlation > max_corr_H:\n",
    "            max_corr_H = spearman_correlation\n",
    "        elif spearman_correlation < min_corr_H:\n",
    "            min_corr_H = spearman_correlation\n",
    "    elif chain == \"L\":\n",
    "        if spearman_correlation > max_corr_L:\n",
    "            max_corr_L = spearman_correlation\n",
    "        elif spearman_correlation < min_corr_L:\n",
    "            min_corr_L = spearman_correlation\n",
    "\n",
    "    \n",
    "    if pearson_correlation > 0 and spearman_correlation > 0:\n",
    "        result_dict[region][\"positive_corr_df\"][chain][\"both\"][custom_name] = region_value\n",
    "    elif pearson_correlation < 0 and spearman_correlation < 0:\n",
    "        result_dict[region][\"negative_corr_df\"][chain][\"both\"][custom_name] = region_value\n",
    "    elif pearson_correlation < 0 and spearman_correlation > 0:\n",
    "        result_dict[region][\"positive_corr_df\"][chain][\"spearman\"][custom_name] = region_value\n",
    "    elif pearson_correlation > 0 and spearman_correlation < 0:\n",
    "        result_dict[region][\"positive_corr_df\"][chain][\"pearson\"][custom_name] = region_value\n",
    "    else:\n",
    "        unknown_dataframes[custom_name] = region_value\n",
    "    \n",
    "    return pearson_correlation, spearman_correlation, variance, std_dev, min_corr_H, max_corr_H, min_corr_L, max_corr_L\n",
    "\n",
    "for custom_name, df in dataframes.items():\n",
    "    for region in regions:\n",
    "        for chain in [\"H\", \"L\"]:\n",
    "            calculate_correlation_regions(df, chain, result_dict, custom_name)\n",
    "print(f\"Overall Minimum Spearman Correlation for Chain H: {min_corr_H}\")\n",
    "print(f\"Overall Maximum Spearman Correlation for Chain H: {max_corr_H}\")\n",
    "print(f\"Overall Minimum Spearman Correlation for Chain L: {min_corr_L}\")\n",
    "print(f\"Overall Maximum Spearman Correlation for Chain L: {max_corr_L}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c44a8e-b04c-48c1-8a1b-86bb4d79da6e",
   "metadata": {},
   "source": [
    "## Print length of lists \n",
    "Printing counts of positive and negative correlations (structures) for each region and antibody types (H and L) using various methods (both, Pearson, Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad677a-ab42-4a6b-93a4-4a2ae01ceae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regions = [\"FR1-A\", \"FR1-B\", \"CDR1\", \"FR2-C\", \"FR2-C'\", \"CDR2\", 'FR3-C\"', \"FR3-D\", \"FR3-E\", \"FR3-F\", \"CDR3\", \"FR4\"]\n",
    "\n",
    "for region in regions:\n",
    "    positive_corr_H_both = len(result_dict[region][\"positive_corr_df\"][\"H\"][\"both\"])\n",
    "    positive_corr_L_both = len(result_dict[region][\"positive_corr_df\"][\"L\"][\"both\"])\n",
    "    negative_corr_H_both = len(result_dict[region][\"negative_corr_df\"][\"H\"][\"both\"])\n",
    "    negative_corr_L_both = len(result_dict[region][\"negative_corr_df\"][\"L\"][\"both\"])\n",
    "\n",
    "    positive_corr_H_pearson = len(result_dict[region][\"positive_corr_df\"][\"H\"][\"pearson\"])\n",
    "    positive_corr_L_pearson = len(result_dict[region][\"positive_corr_df\"][\"L\"][\"pearson\"])\n",
    "    negative_corr_H_pearson = len(result_dict[region][\"negative_corr_df\"][\"H\"][\"pearson\"])\n",
    "    negative_corr_L_pearson = len(result_dict[region][\"negative_corr_df\"][\"L\"][\"pearson\"])\n",
    "\n",
    "    positive_corr_H_spearman = len(result_dict[region][\"positive_corr_df\"][\"H\"][\"spearman\"])\n",
    "    positive_corr_L_spearman= len(result_dict[region][\"positive_corr_df\"][\"L\"][\"spearman\"])\n",
    "    negative_corr_H_spearman = len(result_dict[region][\"negative_corr_df\"][\"H\"][\"spearman\"])\n",
    "    negative_corr_L_spearman = len(result_dict[region][\"negative_corr_df\"][\"L\"][\"spearman\"])\n",
    "\n",
    "    print(f\"Region: {region}\")\n",
    "    print(f\"positive_corr_H_both: {positive_corr_H_both}\")\n",
    "    print(f\"negative_corr_H_both: {negative_corr_H_both}\")\n",
    "    print(f\"positive_corr_H_pearson: {positive_corr_H_pearson}\")\n",
    "    print(f\"negative_corr_H_pearson: {negative_corr_H_pearson}\")\n",
    "    print(f\"positive_corr_H_spearman: {positive_corr_H_spearman}\")\n",
    "    print(f\"negative_corr_H_spearman: {negative_corr_H_spearman}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    print(f\"positive_corr_L_both: {positive_corr_L_both}\")\n",
    "    print(f\"positive_corr_L_pearson: {positive_corr_L_pearson}\")\n",
    "    print(f\"positive_corr_L_spearman: {positive_corr_L_spearman}\")\n",
    "    print(f\"negative_corr_L_both: {negative_corr_L_both}\")\n",
    "    print(f\"negative_corr_L_pearson: {negative_corr_L_pearson}\")\n",
    "    print(f\"negative_corr_L_spearman: {negative_corr_L_spearman}\")\n",
    "    print(\"\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc437a03-d57b-49f0-82e8-baef44bd7b5c",
   "metadata": {},
   "source": [
    "## In certain cases, there are structures which do not have certain regions (e.g. CDR2) this is something to look into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e2c96-bf62-4ffc-ad04-81ab97f07028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regions = [\"FR1-A\", \"FR1-B\", \"CDR1\", \"FR2-C\", \"FR2-C'\", \"CDR2\", 'FR3-C\"', \"FR3-D\", \"FR3-E\", \"FR3-F\", \"CDR3\", \"FR4\"]\n",
    "\n",
    "\n",
    "for custom_name, df in unknown_dataframes.items():\n",
    "    for region in regions:\n",
    "        chain_value = df[df[\"chain\"] == chain]\n",
    "        region_value = chain_value[chain_value[\"region\"] == region]\n",
    "        pearson_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"])\n",
    "        spearman_correlation = region_value[\"AntiBERTy normalised\"].corr(region_value[\"Rosetta normalised\"], method=\"spearman\")\n",
    "        variability = np.var(region_value[\"AntiBERTy normalised\"] - region_value[\"Rosetta normalised\"])\n",
    "        std_dev = np.sqrt(variability)\n",
    "        # print(custom_name, region, chain,  pearson_correlation, spearman_correlation, variability, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c0b9b-6d9c-4426-9397-972f4803b4b3",
   "metadata": {},
   "source": [
    "## Regional data - dataframe\n",
    "Taking the correlations calculated back for each region of the antibody, we take this and create a dataframe which will contain the type of correlation  (positive vs negative), by which method (only pearson, only spearman or both), as well as the region and which antibody falls in this category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5563301-33ab-4f06-888c-fa025f10498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_region_list = []\n",
    "positive = \"positive_corr_df\"\n",
    "negative = \"negative_corr_df\"\n",
    "\n",
    "def summary_dataframe(result_dict):\n",
    "    for region, region_dict in result_dict.items():\n",
    "        for correlation_type, correlation_type_dict in region_dict.items():\n",
    "            if correlation_type == positive:\n",
    "                for chain, chain_dict in correlation_type_dict.items():\n",
    "                    for correlation, df_dict in chain_dict.items():\n",
    "                        for antibody_iden, df in df_dict.items():\n",
    "                            data_region_list.append({\n",
    "                                \"Region\": region,\n",
    "                                \"Chain\": chain,\n",
    "                                \"Correlation type\": \"Positive\",\n",
    "                                \"Method\": correlation,\n",
    "                                \"Antibody IDEN code\": antibody_iden,\n",
    "                            })\n",
    "            elif correlation_type == negative:\n",
    "                for chain, chain_dict in correlation_type_dict.items():\n",
    "                    for correlation, df_dict in chain_dict.items():\n",
    "                        for antibody_iden, df in df_dict.items():\n",
    "                            data_region_list.append({\n",
    "                                \"Region\": region,\n",
    "                                \"Chain\": chain,\n",
    "                                \"Correlation type\": \"Negative\",\n",
    "                                \"Method\": correlation,\n",
    "                                \"Antibody IDEN code\": antibody_iden,\n",
    "                            })\n",
    "\n",
    "\n",
    "summary_dataframe(result_dict)\n",
    "\n",
    "regional_data = pd.DataFrame(data_region_list)\n",
    "# regional_data.to_csv(\"test.csv\", index = False)\n",
    "\n",
    "display(regional_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7c2ae-8f6a-4232-bb37-7041a88a9475",
   "metadata": {},
   "source": [
    "## Split regional Dataframe \n",
    "we can then take this dataframe and split it by the region (e.g. CDR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f05641-9fa1-41ed-a6b7-a3615ecd88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"Region Correlations DF\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "region_dataframes = {}\n",
    "dataframes_path = \"Region Correlations DF/\"\n",
    "\n",
    "for region, group in regional_data.groupby(\"Region\"):\n",
    "    region_dataframes[region + '_dataframe'] = group\n",
    "    file_path = os.path.join(dataframes_path, f\"{region}_dataframe.csv\")\n",
    "    group.to_csv(file_path, index = False)\n",
    "\n",
    "display(region_dataframes[\"CDR2_dataframe\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
